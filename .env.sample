# This is a .env.sample file.
# Duplicate this file as .env or rename it
# and set the environment variables to match your
# desired config.

# ===== Django =====
DJANGO_SECRET_KEY='secret-key'
DEBUG=False
ALLOWED_HOSTS='localhost,127.0.0.1,[::1],0.0.0.0'
CSRF_TRUSTED_ORIGINS='http://127.0.0.1:8000,http://0.0.0.0:8000,http://localhost:8000'
CORS_ALLOWED_ORIGINS='http://127.0.0.1:8000,http://0.0.0.0:8000,http://localhost:8000'

# ===== Django database =====
DB_NAME='movies_database'
DB_USER='app'
DB_PASSWORD='123qwe'
DB_HOST='postgres'
# DB_PORT=5432

# ===== Django Admin =====
DJANGO_SUPERUSER_USERNAME='admin'
DJANGO_SUPERUSER_EMAIL='admin@default.com'
DJANGO_SUPERUSER_PASSWORD='admin12345'

# ===== PostgreSQL =====
POSTGRES_DB='movies_database'
POSTGRES_USER='app'
POSTGRES_PASSWORD='123qwe'
POSTGRES_HOST='postgres'
POSTGRES_PORT=5432

# ===== SQLite path =====
SQLITE_DB='db.sqlite'

# ===== Api variables =====
VALUE_PAGE=50

# ===== Redis =====
REDIS_HOST='redis'
REDIS_PORT=6379
REDIS_DB=0
REDIS_DECODE=True

# ===== Elasticsearch =====
ELASTICSEARCH_ENDPOINT='http://es01:9200'
ELASTICSEARCH_INDEX='movies'

# Variable to set the seconds the scheduler should wait to repeat the task.
# If set the variable for more than 1 second, it may take a long time to 
# load all the data. The value must be an integer.
# 1 second spend about 10 minutes to load in batches of 100 all the data.
SCHEDULER_SECONDS=1

# ===== Docker compose variales =====
COMPOSE_VERSION=3
POSTGRES_VERSION='14-alpine'
INTERVAL_CHECK='5s'
TIMEOUT_CHECK='60s'
RETRIES_CHECK=15
START_CHECK='30s'
ELASTICSEARCH_VERSION='8.12.1'
ELASTICSEARCH_PORTS='9200:9200'
REDIS_VERSION='7.2.4'
REDIS_PORT_EXP='6379:6379'
NGINX_VERSION='1.19.2'
NGINX_PORTS='8000:80'
